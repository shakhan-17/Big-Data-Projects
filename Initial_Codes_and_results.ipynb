{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTC/sAZ0qdHawOln5FOfYr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shakhan-17/Big-Data-Projects/blob/main/Initial_Codes_and_results.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**PROJECT TITLE:** A COMPREHENSIVE APPROACH TO ADDRESS THE COLD START PROBLEM IN RECOMMENDER SYSTEMS"
      ],
      "metadata": {
        "id": "Q_Z_boL3Tpe6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initial Results and Code**\n",
        "\n",
        "**Submitted by:** Md Shamsul Arif Khan\n",
        "\n",
        "**Student ID:** 501140715\n"
      ],
      "metadata": {
        "id": "MpvUPPXLSX6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Supervisor Name:** Ceni Babaoglu\n",
        "\n",
        "**Course Code:** CIND820"
      ],
      "metadata": {
        "id": "kqOHT09TS_Bm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date of Submission:** November 15, 2023"
      ],
      "metadata": {
        "id": "iD1tKHrxT3Hw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing necessary libraries and tools**"
      ],
      "metadata": {
        "id": "Gu_d--iVQgYa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z672yJaDNPmx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from zipfile import ZipFile\n",
        "import urllib.request\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the datasets**"
      ],
      "metadata": {
        "id": "EBkYi1dUQzwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Link for the MovieLens small dataset\n",
        "url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "file_name = 'movielens_small.zip'\n",
        "\n",
        "# Download and extract datasets\n",
        "if not os.path.exists(file_name):\n",
        "    urllib.request.urlretrieve(url, file_name)\n",
        "    with ZipFile(file_name, 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "\n",
        "# Load datasets into Pandas DataFrames\n",
        "movies = pd.read_csv('ml-latest-small/movies.csv')\n",
        "ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
        "tags = pd.read_csv('ml-latest-small/tags.csv')\n",
        "links = pd.read_csv('ml-latest-small/links.csv')"
      ],
      "metadata": {
        "id": "QEloxQG4Qs5b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Processing the Datasets**"
      ],
      "metadata": {
        "id": "2ocI1visRMga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge tags into movies DataFrame\n",
        "movies = pd.merge(movies, tags, on='movieId', how='left')\n",
        "\n",
        "# Merge links with movies DataFrame\n",
        "movies = pd.merge(movies, links, on='movieId', how='left')\n",
        "\n",
        "# Clean NaN values in tags, genres, and IMDbId columns\n",
        "movies['tag'] = movies['tag'].fillna('')\n",
        "movies['genres'] = movies['genres'].str.replace('|', ' ')\n",
        "\n",
        "# Combine relevant information for movie features\n",
        "movies['features'] = movies['genres'] + ' ' + movies['tag']\n",
        "\n",
        "# Split data into training and test sets for collaborative filtering\n",
        "train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a user-item matrix for collaborative filtering\n",
        "train_user_item_matrix = train_data.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "\n",
        "# Convert the DataFrame into a sparse matrix\n",
        "train_user_item_matrix_sparse = csr_matrix(train_user_item_matrix.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iEPxzfsRLlz",
        "outputId": "c0e38435-96b1-42c5-c85f-a9e6f3edab40"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-ad8a685afb9f>:9: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  movies['genres'] = movies['genres'].str.replace('|', ' ')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building recommender system using Collaborative Filtering method**"
      ],
      "metadata": {
        "id": "ItPWHQPZRWlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collaborative filtering using matrix factorization (SVD)\n",
        "num_factors = 50\n",
        "U, sigma, Vt = svds(train_user_item_matrix_sparse, k=num_factors)\n",
        "sigma = np.diag(sigma)\n",
        "predicted_ratings = np.dot(np.dot(U, sigma), Vt)"
      ],
      "metadata": {
        "id": "HUH8Xhv_OYW2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to recommend movies based on collaborative filtering\n",
        "def collaborative_filtering_recommendations(user_id, predicted_ratings, num_recommendations=10):\n",
        "    user_ratings = predicted_ratings[user_id - 1]\n",
        "    sorted_indices = user_ratings.argsort()[::-1]\n",
        "    user_seen_movies = train_user_item_matrix.columns[train_user_item_matrix.loc[user_id].gt(0)].tolist()\n",
        "\n",
        "    recommended_movies = []\n",
        "    for idx in sorted_indices:\n",
        "        movie_id = idx + 1\n",
        "        if movie_id not in user_seen_movies:\n",
        "            movie_info = movies[movies['movieId'] == movie_id]['title'].values\n",
        "            if len(movie_info) > 0:\n",
        "                movie_title = movie_info[0]\n",
        "                recommended_movies.append((movie_title, user_ratings[idx]))\n",
        "                if len(recommended_movies) >= num_recommendations:\n",
        "                    break\n",
        "\n",
        "    return recommended_movies"
      ],
      "metadata": {
        "id": "28aSVEHDOebK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collaborative Filtering Example\n",
        "user_id_collab = 1\n",
        "collab_recommended_movies = collaborative_filtering_recommendations(user_id_collab, predicted_ratings)\n",
        "print(f\"Collaborative Filtering Recommendations for User {user_id_collab}:\")\n",
        "for idx, (movie, rating) in enumerate(collab_recommended_movies, start=1):\n",
        "    print(f\"{idx}. {movie} (Predicted Rating: {rating})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzYbRYOKP0XF",
        "outputId": "820f127c-3208-4ede-fc40-6d4f6733ca2c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collaborative Filtering Recommendations for User 1:\n",
            "1. That Darn Cat (1997) (Predicted Rating: 5.015913227046896)\n",
            "2. Muppet Christmas Carol, The (1992) (Predicted Rating: 4.870666524016725)\n",
            "3. Perfect World, A (1993) (Predicted Rating: 4.757768102863207)\n",
            "4. Fear and Loathing in Las Vegas (1998) (Predicted Rating: 4.679545505282457)\n",
            "5. Inspector General, The (1949) (Predicted Rating: 4.659823207461228)\n",
            "6. Interview with the Vampire: The Vampire Chronicles (1994) (Predicted Rating: 4.458921745950045)\n",
            "7. Wild Reeds (Les roseaux sauvages) (1994) (Predicted Rating: 4.231743713145592)\n",
            "8. 8 Seconds (1994) (Predicted Rating: 3.97254336381257)\n",
            "9. American Buffalo (1996) (Predicted Rating: 3.9537390735075695)\n",
            "10. Crow: City of Angels, The (1996) (Predicted Rating: 3.6317791961621655)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building recommender system using Content-based Filtering method**"
      ],
      "metadata": {
        "id": "HkAHn_yBR75g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the similarity matrix using cosine similarity for content-based filtering\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(movies['features'].values.astype('U'))\n",
        "item_similarity = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Function to recommend movies based on content-based filtering\n",
        "def content_based_recommendations(movie_title, similarity_matrix, num_recommendations=10):\n",
        "    movie_index = movies[movies['title'] == movie_title].index.values[0]\n",
        "    similar_scores = similarity_matrix[movie_index]\n",
        "    similar_movies_indices = similar_scores.argsort()[::-1][1:]  # Exclude the movie itself\n",
        "    similar_movies = movies.iloc[similar_movies_indices]\n",
        "    return similar_movies[['title', 'genres', 'imdbId']]\n",
        "\n",
        "\n",
        "# Content-Based Filtering Example\n",
        "movie_title_content = 'Toy Story (1995)'\n",
        "content_recommended_movies = content_based_recommendations(movie_title_content, item_similarity)\n",
        "print(\"\\nContent-Based Filtering Recommendations:\")\n",
        "print(content_recommended_movies.head(10))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5FI_bTvPTnb",
        "outputId": "75851b8a-6580-4d8f-9967-83fdc2b36eaa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Content-Based Filtering Recommendations:\n",
            "                                                   title  \\\n",
            "1                                       Toy Story (1995)   \n",
            "3214                                  Toy Story 2 (1999)   \n",
            "3217                                  Toy Story 2 (1999)   \n",
            "2484                                Bug's Life, A (1998)   \n",
            "8672                                           Up (2009)   \n",
            "4633                               Monsters, Inc. (2001)   \n",
            "11499                                       Moana (2016)   \n",
            "3966                    Emperor's New Groove, The (2000)   \n",
            "9544   Asterix and the Vikings (Astérix et les Viking...   \n",
            "10948                           The Good Dinosaur (2015)   \n",
            "\n",
            "                                            genres   imdbId  \n",
            "1      Adventure Animation Children Comedy Fantasy   114709  \n",
            "3214   Adventure Animation Children Comedy Fantasy   120363  \n",
            "3217   Adventure Animation Children Comedy Fantasy   120363  \n",
            "2484           Adventure Animation Children Comedy   120623  \n",
            "8672            Adventure Animation Children Drama  1049413  \n",
            "4633   Adventure Animation Children Comedy Fantasy   198781  \n",
            "11499  Adventure Animation Children Comedy Fantasy  3521164  \n",
            "3966   Adventure Animation Children Comedy Fantasy   120917  \n",
            "9544   Adventure Animation Children Comedy Fantasy   371552  \n",
            "10948  Adventure Animation Children Comedy Fantasy  1979388  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building recommender system using Hybrid Filtering method**"
      ],
      "metadata": {
        "id": "ZVcgCf0vR_PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for hybrid recommendations combining collaborative and content-based approaches\n",
        "def hybrid_recommendations(user_id, movie_title, num_recommendations=10):\n",
        "    collab_recommended = collaborative_filtering_recommendations(user_id, predicted_ratings)\n",
        "    content_recommended = content_based_recommendations(movie_title, item_similarity)\n",
        "\n",
        "    # Merge recommendations from both models\n",
        "    hybrid_recommendations = []\n",
        "    collab_titles = [title for title, _ in collab_recommended]\n",
        "    for idx, (title, _) in enumerate(collab_recommended):\n",
        "        if title not in collab_titles:\n",
        "            hybrid_recommendations.append((title, idx+1))\n",
        "\n",
        "    content_titles = [title for title in content_recommended['title']]\n",
        "    for idx, (title, _) in enumerate(content_recommended.values):\n",
        "        if title not in content_titles:\n",
        "            hybrid_recommendations.append((title, idx+1))\n",
        "\n",
        "    hybrid_recommendations = sorted(hybrid_recommendations, key=lambda x: x[1])\n",
        "    return [movie[0] for movie in hybrid_recommendations[:num_recommendations]]\n",
        "\n"
      ],
      "metadata": {
        "id": "98cvn0fWOlD7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Function for hybrid recommendations combining collaborative and content-based approaches\n",
        "def hybrid_recommendations(user_id, movie_title, num_recommendations=10):\n",
        "    collab_recommended = collaborative_filtering_recommendations(user_id, predicted_ratings)\n",
        "    content_recommended = content_based_recommendations(movie_title, item_similarity)\n",
        "\n",
        "    hybrid_recommendations = []\n",
        "    collab_titles = [title for title, _ in collab_recommended]\n",
        "    for idx, (title, _) in enumerate(collab_recommended):\n",
        "        if title not in collab_titles:\n",
        "            hybrid_recommendations.append((title, idx+1))\n",
        "\n",
        "    content_titles = [title for title in content_recommended['title']]\n",
        "    for title in content_titles:\n",
        "        if title not in collab_titles:\n",
        "            hybrid_recommendations.append((title, idx+1))\n",
        "\n",
        "    hybrid_recommendations = sorted(hybrid_recommendations, key=lambda x: x[1])\n",
        "    return [movie[0] for movie in hybrid_recommendations[:num_recommendations]]\n",
        "\n",
        "\n",
        "\n",
        "# Hybrid Filtering Example\n",
        "user_id_hybrid = 1\n",
        "hybrid_recommended_movies = hybrid_recommendations(user_id_hybrid, movie_title_content)\n",
        "print(f\"\\nHybrid Recommendations for User {user_id_hybrid} based on '{movie_title_content}':\")\n",
        "for idx, movie in enumerate(hybrid_recommended_movies, start=1):\n",
        "    print(f\"{idx}. {movie}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbQT4oG7QOHn",
        "outputId": "1ed030f2-3365-4cda-af52-b2873bb5fcd8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hybrid Recommendations for User 1 based on 'Toy Story (1995)':\n",
            "1. Toy Story (1995)\n",
            "2. Toy Story 2 (1999)\n",
            "3. Toy Story 2 (1999)\n",
            "4. Bug's Life, A (1998)\n",
            "5. Up (2009)\n",
            "6. Monsters, Inc. (2001)\n",
            "7. Moana (2016)\n",
            "8. Emperor's New Groove, The (2000)\n",
            "9. Asterix and the Vikings (Astérix et les Vikings) (2006)\n",
            "10. The Good Dinosaur (2015)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating output for the initial codes and results"
      ],
      "metadata": {
        "id": "pMuvmrBPVa1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the tools\n",
        "import nbconvert\n",
        "\n",
        "# To upload the Initial Codes and results file ( \"Initial Codes and results.ipynb\" ) from PC\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# To generate the pdf file\n",
        "!jupyter nbconvert --to pdf /content/Initial Codes and results.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZNckUxTLVhTD",
        "outputId": "102d9867-12e1-4468-dfcc-8d2206b8e067"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d5eb50cd-876a-4d3c-a37b-8e5862999e96\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d5eb50cd-876a-4d3c-a37b-8e5862999e96\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] WARNING | pattern '/content/Initial' matched no files\n",
            "[NbConvertApp] WARNING | pattern 'Codes' matched no files\n",
            "[NbConvertApp] WARNING | pattern 'and' matched no files\n",
            "[NbConvertApp] WARNING | pattern 'results.ipynb' matched no files\n",
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    overwrite base name use for output files.\n",
            "                can only be used when converting one notebook at a time.\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}